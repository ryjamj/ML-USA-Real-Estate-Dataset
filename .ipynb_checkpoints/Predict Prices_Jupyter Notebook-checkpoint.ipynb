{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "335a9d1f",
   "metadata": {},
   "source": [
    "# ML to Predict Home Prieces\n",
    "\n",
    "### Introduction\n",
    "USA Real Estate - Predict priceÂ¶\n",
    "About Dataset\n",
    "This dataset contains Real Estate listings in the US broken by State and zip code.\n",
    "Data was collected via web scraping using python libraries.\n",
    "\n",
    "### Columns\n",
    "- status\n",
    "- price\n",
    "- bed\n",
    "- bath\n",
    "- acre_lot\n",
    "- full_address\n",
    "- street\n",
    "- city\n",
    "- state\n",
    "- zip_code\n",
    "- house_size\n",
    "- sold_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30839264",
   "metadata": {},
   "source": [
    "## To Do & Goals\n",
    "- Remove Outliers on price\n",
    "- Explore missingno documentation.  Can I create a function that also returns the % of values that are missing per row?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93f73432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working with data\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import geopandas as gpd # the library that lets us read in shapefiles\n",
    "#import geoplot as gplt # for plotting maps #having trouble getting this to install\n",
    "\n",
    "# visulizaiton\n",
    "from termcolor import colored # colored text\n",
    "import missingno as msno # visuzlise missing data in a matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cleanup\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd205935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current directory = C:\\Users\\ryjam\\OneDrive\\Documents\\Ry Training\\Personal Projects\\USA-Real-Estate-Dataset\n"
     ]
    }
   ],
   "source": [
    "# Setting work directory\n",
    "cwd = os.getcwd()\n",
    "print(\"current directory = \" + cwd)\n",
    "\n",
    "# os.chdir(\"../NotEssentialData\")\n",
    "# print(\"new directory = \" + os.path.abspath(os.curdir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37c8c14",
   "metadata": {},
   "source": [
    "## add this to ReadMe\n",
    "- https://www.kaggle.com/datasets/ahmedshahriarsakib/usa-real-estate-dataset?resource=download\n",
    "This dataset contains Real Estate listings in the US broken by State and zip code. Data was collected via web scraping using python libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59314a82",
   "metadata": {},
   "source": [
    "## Data Exploration and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ffdbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file - zip\n",
    "\n",
    "fileInput = \"data/realtor-data.zip\"\n",
    "df = pd.read_csv(fileInput, compression='zip').reset_index(drop=True)\n",
    "print(len(df))\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad44d2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46af9755",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f059ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore missing values\n",
    "\n",
    "print(df.isnull().sum())\n",
    "msno.matrix(df, figsize=(10,5), fontsize=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e21d6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # large dataset, having difficulty getting this to work\n",
    "\n",
    "# # Pair Plot features agaist one another\n",
    "# sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df9e354",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot a scatter plot of price versus features of interest\n",
    "\n",
    "FeatureList = ['bed', 'bath', 'acre_lot', 'house_size', 'status', 'state']\n",
    "for col in FeatureList:\n",
    "    fig = plt.figure(figsize=(11, 3))\n",
    "    ax = fig.gca()\n",
    "    plt.scatter(x=df[col], y=df['price'])\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"price\")\n",
    "    ax.set_title(col)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512decf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to show the distriubtion of numieric features\n",
    "def ShowDistributionFuc(var):\n",
    "    '''\n",
    "    This function will only works with numierc values.\n",
    "    Shows statistics & displays a histogram - boxplot combo.\n",
    "    '''\n",
    "\n",
    "    # Get statistics\n",
    "    min_val = var.min()\n",
    "    mean_val = var.mean()\n",
    "    med_val = var.median()\n",
    "    mod_val = var.mode()[0]\n",
    "    max_val = var.max()\n",
    "    print(colored('Min: ' + str(min_val), 'grey'))\n",
    "    print(colored('Mean: ' + str(mean_val), 'cyan'))\n",
    "    print(colored('Median: ' + str(med_val), 'red'))\n",
    "    print(colored('Mode: ' + str(mod_val), 'yellow'))\n",
    "    print(colored('Max: ' + str(max_val), 'grey'))\n",
    "\n",
    "\n",
    "    # Create a figure for 2 subplots (2 rows, 1 column)(historgram & boxplot)\n",
    "    fig, ax = plt.subplots(2, 1, figsize = (10,4))\n",
    "    fig.suptitle('Data Distribution')\n",
    "\n",
    "    # Plot the histogram, add lines for the mean, median, and mode\n",
    "    ax[0].hist(var)\n",
    "    ax[0].set_ylabel('Frequency')\n",
    "    ax[0].axvline(x=min_val, color = 'gray', linestyle='dashed', linewidth = 2)\n",
    "    ax[0].axvline(x=mean_val, color = 'cyan', linestyle='dashed', linewidth = 2)\n",
    "    ax[0].axvline(x=med_val, color = 'red', linestyle='dashed', linewidth = 2)\n",
    "    ax[0].axvline(x=mod_val, color = 'yellow', linestyle='dashed', linewidth = 2)\n",
    "    ax[0].axvline(x=max_val, color = 'gray', linestyle='dashed', linewidth = 2)\n",
    "\n",
    "    # Plot the boxplot\n",
    "    ax[1].boxplot(var, vert=False)\n",
    "    ax[1].set_xlabel('Value')\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0891c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show Distribution of some key features of interest\n",
    "\n",
    "FeatureList = ['price', 'bed', 'bath', 'acre_lot', 'house_size']\n",
    "for col in FeatureList:\n",
    "    print(f'Feature: ', col)\n",
    "    ShowDistributionFuc(df[col])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a48b203",
   "metadata": {},
   "source": [
    "## Data Assumptions & Notes\n",
    "Drawn conclusions after Data Exploration and Analysis\n",
    "\n",
    "Notes\n",
    "- Some outlier with a price greater than $800M\n",
    "- Number of units with high value of beds and baths, which seem odd for homes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62253c46",
   "metadata": {},
   "source": [
    "## Clean the Data\n",
    "- create new working dataframe\n",
    "- remove duplicate entries\n",
    "- remove outliers\n",
    "    - households with a price >= $1,000,000\n",
    "    - remove households with a bed >= 60\n",
    "- normlize the data\n",
    "- One-Hot encoding status & state valeus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfac23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dataframe\n",
    "# remove duplicate entries\n",
    "newColumns = ['price', 'bed', 'bath', 'acre_lot', 'house_size', 'status', 'state', 'full_address']\n",
    "df1 = df[newColumns].copy().dropna().drop_duplicates().reset_index(drop=True)\n",
    "print(len(df1))\n",
    "df1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e08660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove households with pirce >= $800,000\n",
    "df1 = df1[df1['price'] < 800000]\n",
    "print(len(df1))\n",
    "print(ShowDistributionFuc(df1['price']))\n",
    "df1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ada680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove households with bed >= 6\n",
    "df1 = df1[df1['bed'] < 6]\n",
    "print(len(df1))\n",
    "print(ShowDistributionFuc(df1['bed']))\n",
    "df1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02a14c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove households with bath >= 5\n",
    "df1 = df1[df1['bath'] < 5]\n",
    "print(len(df1))\n",
    "print(ShowDistributionFuc(df1['bath']))\n",
    "df1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d1bfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove households with acre_lot >= 1\n",
    "df1 = df1[df1['acre_lot'] < 1]\n",
    "print(len(df1))\n",
    "print(ShowDistributionFuc(df1['acre_lot']))\n",
    "df1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e795e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dataframe, used for one-hot encoding and X & Y training\n",
    "# drop full_address\n",
    "# One-Hot encode the status & state values\n",
    "df1_ohe = df1.copy()\n",
    "df1_ohe = df1_ohe.drop(['full_address'], axis=1) # drop full_address\n",
    "df1_ohe = pd.get_dummies(df1_ohe, columns=[\"status\"], drop_first=False)\n",
    "df1_ohe = pd.get_dummies(df1_ohe, columns=[\"state\"], drop_first=False)\n",
    "df1_ohe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5aff43",
   "metadata": {},
   "source": [
    "## Train & Fit a Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc9820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# use price as the label\n",
    "\n",
    "X, y = df1_ohe[df1_ohe.columns[1:-1]].values, df1_ohe[df1_ohe.columns[0]].values\n",
    "\n",
    "# Split data 70%-30% into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "print ('Training Set: %d, rows\\nTest Set: %d rows' % (X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57c3267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabe7c5b",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84919872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Get predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Display metrics\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"MSE:\", mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R2:\", r2)\n",
    "\n",
    "# Plot predicted vs actual\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Predictions vs Actuals')\n",
    "z = np.polyfit(y_test, predictions, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_test,p(y_test), color='magenta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cab3fb",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "- let's try normalzing the datagframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd00e6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = df1.copy()\n",
    "# # apply normalization techniques\n",
    "# for column in df2.columns:\n",
    "#     df2[column] = df2[column]  / df2[column].abs().max()\n",
    "# df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651d4be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = df2[df2.columns[1:-1]].values, df2[df2.columns[0]].values\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "# print ('Training Set: %d, rows\\nTest Set: %d rows' % (X_train.shape[0], X_test.shape[0]))\n",
    "# model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64806dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get predictions\n",
    "# predictions = model.predict(X_test)\n",
    "\n",
    "# # Display metrics\n",
    "# mse = mean_squared_error(y_test, predictions)\n",
    "# print(\"MSE:\", mse)\n",
    "# rmse = np.sqrt(mse)\n",
    "# print(\"RMSE:\", rmse)\n",
    "# r2 = r2_score(y_test, predictions)\n",
    "# print(\"R2:\", r2)\n",
    "\n",
    "# # Plot predicted vs actual\n",
    "# plt.scatter(y_test, predictions)\n",
    "# plt.xlabel('Actual Labels')\n",
    "# plt.ylabel('Predicted Labels')\n",
    "# plt.title('Predictions vs Actuals')\n",
    "# z = np.polyfit(y_test, predictions, 1)\n",
    "# p = np.poly1d(z)\n",
    "# plt.plot(y_test,p(y_test), color='magenta')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a78ee01",
   "metadata": {},
   "source": [
    "## Use the Trained Model\n",
    "- Save your trained model\n",
    "- Use it to predict the price of a home with dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f9a4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "\n",
    "# filename = './home_price_model.pkl'\n",
    "# joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9114b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dummy data\n",
    "# # An array of features for each transaction (don't include the transaction date)\n",
    "# newColumns = ['status', 'price', 'bed', 'bath', 'acre_lot', 'state', 'house_size']\n",
    "# # X_new = np.array([[16.2,289.3248,5,24.98203,121.54348],\n",
    "# #                   [13.6,4082.015,0,24.94155,121.5038]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b374e9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the model from the file\n",
    "# loaded_model = joblib.load(filename)\n",
    "\n",
    "# # Use the model to predict unit price\n",
    "# results = loaded_model.predict(X_new)\n",
    "# print('Predictions:')\n",
    "# for prediction in results:\n",
    "#     print(round(prediction,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb4a85f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2584564",
   "metadata": {},
   "source": [
    "## Convert street address to lat & long\n",
    "- Use smaller data set for ease of use (use NJ).\n",
    "- Already Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a034c4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.groupby(['state'])['state'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd00423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1_NJ = df1.copy()\n",
    "# df1_NJ = df1_NJ[df1_NJ['state'] == 'New Jersey'].reset_index(drop=True)\n",
    "# print(len(df1_NJ))\n",
    "# df1_NJ.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dbf404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # Have to incdlue a rate limitier to use Nominatim service on large datasets.\n",
    "# from geopy.geocoders import Nominatim\n",
    "# geolocator = Nominatim(user_agent=\"myPracApp\")\n",
    "\n",
    "# from geopy.extra.rate_limiter import RateLimiter\n",
    "# geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)\n",
    "# df1_NJ['location'] = df1_NJ['full_address'].apply(geocode)\n",
    "# df1_NJ['point'] = df1_NJ['location'].apply(lambda loc: tuple(loc.point) if loc else None)\n",
    "# df1_NJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8411cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1_NJ.to_csv(\"data/df1_NJ.csv.zip\", index=False, compression=\"zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a71a0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0015dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ad7e252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8899\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>acre_lot</th>\n",
       "      <th>house_size</th>\n",
       "      <th>status</th>\n",
       "      <th>state</th>\n",
       "      <th>full_address</th>\n",
       "      <th>location</th>\n",
       "      <th>point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>333490.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>Katherine, Burlington, NJ, 08016</td>\n",
       "      <td>Katherine Dr, Burlington Township, Burlington ...</td>\n",
       "      <td>(40.0463435, -74.8744182, 0.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  bed  bath  acre_lot  house_size    status       state  \\\n",
       "0  333490.0  3.0   3.0      0.07      1500.0  for_sale  New Jersey   \n",
       "\n",
       "                       full_address  \\\n",
       "0  Katherine, Burlington, NJ, 08016   \n",
       "\n",
       "                                            location  \\\n",
       "0  Katherine Dr, Burlington Township, Burlington ...   \n",
       "\n",
       "                            point  \n",
       "0  (40.0463435, -74.8744182, 0.0)  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input file - zip\n",
    "\n",
    "fileInput = \"data/df1_NJ.zip\"\n",
    "dfl = pd.read_csv(fileInput, compression='zip').reset_index(drop=True)\n",
    "print(len(dfl))\n",
    "dfl.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d0e1570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryjam\\AppData\\Local\\Temp\\ipykernel_4808\\3213025637.py:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  dfl['point'] = dfl['point'].str.replace('(','').str.replace(')','').str.split(',').tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6728\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>acre_lot</th>\n",
       "      <th>house_size</th>\n",
       "      <th>status</th>\n",
       "      <th>state</th>\n",
       "      <th>full_address</th>\n",
       "      <th>location</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>333490.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>Katherine, Burlington, NJ, 08016</td>\n",
       "      <td>Katherine Dr, Burlington Township, Burlington ...</td>\n",
       "      <td>40.046343</td>\n",
       "      <td>-74.874418</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  bed  bath  acre_lot  house_size    status       state  \\\n",
       "0  333490.0  3.0   3.0      0.07      1500.0  for_sale  New Jersey   \n",
       "\n",
       "                       full_address  \\\n",
       "0  Katherine, Burlington, NJ, 08016   \n",
       "\n",
       "                                            location   latitude  longitude  \\\n",
       "0  Katherine Dr, Burlington Township, Burlington ...  40.046343 -74.874418   \n",
       "\n",
       "   index  \n",
       "0      0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfl=dfl.dropna(subset=['point'])\n",
    "dfl['point'] = dfl['point'].str.replace('(','').str.replace(')','').str.split(',').tolist()\n",
    "dfl['latitude'] = dfl['point'].str[0]\n",
    "dfl['longitude'] = dfl['point'].str[1]\n",
    "dfl['latitude'] = dfl['latitude'].astype(float)\n",
    "dfl['longitude'] = dfl['longitude'].astype(float)\n",
    "dfl = dfl.drop(['point'], axis=1)\n",
    "dfl['index'] = dfl.index\n",
    "dfl.to_excel(\"data/NJLocationData.xlsx\", index=False)\n",
    "print(len(dfl))\n",
    "dfl.head(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
